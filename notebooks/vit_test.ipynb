{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import *\n",
    "import torchvision as vision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "df = pd.read_csv('../datasets/processed/pokemon.csv')\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(df[['type1']])\n",
    "types = ohe.transform(df[['type1']]).toarray()\n",
    "chosen = [20, 100, 1, 5, 2]\n",
    "df = df.query('dex  in @chosen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model using custom encoder and decoder\n",
    "class VIencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = models.vit_b_16(weights='IMAGENET1K_V1')\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(1018, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 150528),\n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, image, ptype):\n",
    "        img = Image.open(image)\n",
    "        img = img.convert('RGB')\n",
    "        img = vision.transforms.Resize((224, 224))(img)\n",
    "        img = vision.transforms.ToTensor()(img)\n",
    "        img = img.unsqueeze(0)\n",
    "        tensor = self.encoder(img)\n",
    "        tensor = torch.cat((tensor[0,:], ptype))\n",
    "        outputs = self.decoder(tensor)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a new model using custom encoder and decoder\n",
    "# class VIencoder2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.encoder = models.vit_b_16(weights='IMAGENET1K_V1')\n",
    "#         self.decoder = torch.nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, 3, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 64, 3, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 64, 3, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 3, 3, 1),\n",
    "#             nn.Sigmoid()\n",
    "#             )\n",
    "\n",
    "\n",
    "#     def forward(self, image):\n",
    "#         img = Image.open(image)\n",
    "#         img = img.convert('RGB')\n",
    "#         img = vision.transforms.Resize((224, 224))(img)\n",
    "#         img = vision.transforms.ToTensor()(img)\n",
    "#         img = img.unsqueeze(0)\n",
    "#         tensor = self.encoder(img)\n",
    "#         print(tensor.shape)\n",
    "#         tensor = tensor.resize(31, 32)\n",
    "#         outputs = self.decoder(tensor)\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vie = VIencoder2()\n",
    "vie = torch.load('pokemon_autoencoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune model on pokemon dataset\n",
    "epochs = 5000\n",
    "learning_rate = 0.00001\n",
    "optimizer = torch.optim.Adam(vie.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "    losses = []\n",
    "    for i in df.index:\n",
    "        optimizer.zero_grad()\n",
    "        image = df.loc[i, 'image']\n",
    "        img = Image.open(df['image'][i])\n",
    "        ptype = torch.tensor(types[i, :]).float()\n",
    "        img = img.convert('RGB')\n",
    "        img = vision.transforms.Resize((224, 224))(img)\n",
    "        img = vision.transforms.ToTensor()(img)\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.flatten()\n",
    "        output = vie(image, ptype)\n",
    "        loss = criterion(output, img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    print(f'Epoch {epoch} Loss: {np.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(vie, 'pokemon_autoencoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../datasets/processed/pokemon.csv')\n",
    "outputs = []\n",
    "# show 5 reconstructed images\n",
    "for i in df.index:\n",
    "    # image = Image.open(df['image'][i])\n",
    "    img = df['image'][i]\n",
    "    ptype = torch.tensor(types[i, :]).float()\n",
    "\n",
    "    output = vie(img, ptype)\n",
    "    output = output.view(3, 224, 224)\n",
    "    output = vision.transforms.ToPILImage()(output)\n",
    "    outputs.append(output)\n",
    "    plt.figure(i+10)\n",
    "    plt.imshow(Image.open(img))\n",
    "    plt.show()\n",
    "    plt.figure(i+20)\n",
    "    plt.imshow(output)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
