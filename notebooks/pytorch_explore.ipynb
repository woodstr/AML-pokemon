{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data into a dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_info = pd.read_csv('../datasets/processed/pokemon.csv')\n",
    "pokemon_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHot encoding the Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(df):\n",
    "    \"\"\"Use df to:\n",
    "     - Create unique list of pokemon types\n",
    "     - Loop through Type1 and Type2 column\n",
    "     - Create one-hot encoding for each type\n",
    "     - Return one-hot encoding for each type as numpy array\"\"\"\n",
    "\n",
    "    all_types = df['type1'].to_list() + df['type2'].to_list()\n",
    "    uniques = list(set(all_types))\n",
    "    uniques = [ x for x in uniques if isinstance(x, str) ] # remove nan by keeping only strings\n",
    "    \n",
    "    onehot = np.zeros((len(df), len(uniques)))\n",
    "    for i, row in df.iterrows():\n",
    "        type1 = row['type1']\n",
    "        type2 = row['type2']\n",
    "\n",
    "        # only work with non nan\n",
    "        if isinstance(type1, str):\n",
    "            onehot[i, uniques.index(type1)] = 1\n",
    "        if isinstance(type2, str):\n",
    "            onehot[i, uniques.index(type2)] = 1\n",
    "\n",
    "    return onehot, uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_enc, uniques = onehot(pokemon_info)\n",
    "print(onehot_enc.shape)\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for showing a pokemon and its name and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pokemon(image, types):\n",
    "    \"\"\"Show image with name, types and evolution of pokemon\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.title(types)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "show_pokemon(io.imread(pokemon_info['image'][0]),\n",
    "               onehot_enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    \"\"\"Pokemon dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.pokemon_info = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pokemon_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # img_name = os.path.join(self.root_dir, str(idx+1) + '.png')\n",
    "        img_name = self.pokemon_info['image'][idx]\n",
    "        image = io.imread(img_name)\n",
    "\n",
    "        # onehot encode the types\n",
    "        sample = {'image': image, 'types': onehot_enc[idx]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s instantiate this class and iterate through the data samples. We will print the sizes of first 4 samples and show their landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_dataset = PokemonDataset(csv_file='../datasets/processed/pokemon.csv',\n",
    "                                 root_dir='../datasets/raw/renders_2d/images/')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i, sample in enumerate(pokemon_dataset):\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_pokemon(**sample)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, types = sample['image'], sample['types']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'types': torch.from_numpy(types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = PokemonDataset(csv_file='../datasets/processed/pokemon.csv',\n",
    "                                     root_dir='../datasets/raw/renders_2d/images/',\n",
    "                                     transform=transforms.Compose([ToTensor()]))\n",
    "\n",
    "for i, sample in enumerate(transformed_dataset):\n",
    "    print(i, sample['image'].size(), sample['types'].size())\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataloader and encoding mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "# save dataloader\n",
    "torch.save(dataloader, '../dataloaders/pokemon_dataloader.pth')\n",
    "\n",
    "# save onehot encoding mapping\n",
    "mapping = dict()\n",
    "for idx, i in enumerate(uniques):\n",
    "    mapping[i] = idx\n",
    "\n",
    "import json\n",
    "with open('../datasets/processed/onehot_mapping.json', 'w') as f:\n",
    "    json.dump(mapping, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
